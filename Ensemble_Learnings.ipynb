{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical Questions"
      ],
      "metadata": {
        "id": "PtoyKyKUnzf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Can we use Bagging for regression problems?\n",
        "Answer 1:\n",
        "Yes, Bagging works for regression by averaging predictions from multiple models.\n",
        "\n",
        "Question 2: What is the difference between multiple model training and single model training?\n",
        "Answer 2:\n",
        "Single model uses one algorithm; multiple model combines several for better performance.\n",
        "\n",
        "Question 3: Explain the concept of feature randomness in Random Forest.\n",
        "Answer 3:\n",
        "Each tree considers a random subset of features at each split to reduce correlation.\n",
        "\n",
        "Question 4: What is OOB (Out-of-Bag) Score?\n",
        "Answer 4:\n",
        "A validation score using data not included in bootstrap samples.\n",
        "\n",
        "Question 5: How can you measure the importance of features in a Random Forest model?\n",
        "Answer 5:\n",
        "By checking how much each feature reduces impurity or affects performance when shuffled.\n",
        "\n",
        "Question 6: Explain the working principle of a Bagging Classifier.\n",
        "Answer 6:\n",
        "Trains multiple models on random samples and combines results via majority vote.\n",
        "\n",
        "Question 7: How do you evaluate a Bagging Classifierâ€™s performance?\n",
        "Answer 7:\n",
        "Use accuracy, precision, recall, F1-score, and OOB score if enabled.\n",
        "\n",
        "Question 8: How does a Bagging Regressor work?\n",
        "Answer 8:\n",
        "Trains regressors on different samples and averages their predictions.\n",
        "\n",
        "Question 9: What is the main advantage of ensemble techniques?\n",
        "Answer 9:\n",
        "Higher accuracy and robustness compared to single models.\n",
        "\n",
        "Question 10: What is the main challenge of ensemble methods?\n",
        "Answer 10:\n",
        "Complexity and reduced interpretability.\n",
        "\n",
        "Question 11: Explain the key idea behind ensemble techniques.\n",
        "Answer 11:\n",
        "Combine multiple models to improve prediction accuracy and reduce overfitting.\n",
        "\n",
        "Question 12: What is a Random Forest Classifier?\n",
        "Answer 12:\n",
        "An ensemble of decision trees using bagging and feature randomness for classification.\n",
        "\n",
        "Question 13: What are the main types of ensemble techniques?\n",
        "Answer 13:\n",
        "Bagging, Boosting, and Stacking.\n",
        "\n",
        "Question 14: What is ensemble learning in machine learning?\n",
        "Answer 14:\n",
        "A method that combines multiple models to make better predictions than a single model.\n",
        "\n",
        "Question 15: When should we avoid using ensemble methods?\n",
        "Answer 15:\n",
        "When model interpretability is crucial or data size is too small.\n",
        "\n",
        "Question 16: How does Bagging help in reducing overfitting?\n",
        "Answer 16:\n",
        "By averaging predictions from multiple models trained on different data samples.\n",
        "\n",
        "Question 17: Why is Random Forest better than a single Decision Tree?\n",
        "Answer 17:\n",
        "It reduces overfitting and increases accuracy through ensemble learning.\n",
        "\n",
        "Question 18: What is the role of bootstrap sampling in Bagging?\n",
        "Answer 18:\n",
        "It creates diverse training datasets to build multiple models.\n",
        "\n",
        "Question 19: What are some real-world applications of ensemble techniques?\n",
        "Answer 19:\n",
        "Fraud detection, spam filtering, medical diagnosis, and recommendation systems.\n",
        "\n",
        "Question 20: What is the difference between Bagging and Boosting?\n",
        "Answer 20:\n",
        "Bagging builds models independently; Boosting builds them sequentially with focus on errors."
      ],
      "metadata": {
        "id": "UlUSiuCOnzcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical Questions"
      ],
      "metadata": {
        "id": "pDEkY459nzZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 21: Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy[link text](https://)"
      ],
      "metadata": {
        "id": "YUGmzquTn0PL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH10MfrInx9q"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Question 22: Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "qPkVA0E7qGyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"MSE:\", mean_squared_error(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "56909AERqHAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 23: Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
      ],
      "metadata": {
        "id": "FcepPbheqHKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "importances = model.feature_importances_\n",
        "for name, score in zip(load_breast_cancer().feature_names, importances):\n",
        "    print(f\"{name}: {score}\")\n"
      ],
      "metadata": {
        "id": "q70nUX8qqHUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 24: Train a Random Forest Regressor and compare its performance with a single Decision Tree"
      ],
      "metadata": {
        "id": "sm6xI69AqHc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor().fit(X_train, y_train)\n",
        "rf = RandomForestRegressor().fit(X_train, y_train)\n",
        "print(\"DT MSE:\", mean_squared_error(y_test, dt.predict(X_test)))\n",
        "print(\"RF MSE:\", mean_squared_error(y_test, rf.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "ex5Thv2pqHl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 25: Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier"
      ],
      "metadata": {
        "id": "v1tJdThqqHu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(oob_score=True)\n",
        "model.fit(X, y)\n",
        "print(\"OOB Score:\", model.oob_score_)\n"
      ],
      "metadata": {
        "id": "xtcZLji6qH5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 26: Train a Bagging Classifier using SVM as a base estimator and print accuracy"
      ],
      "metadata": {
        "id": "MbBAmJLMqIBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = BaggingClassifier(base_estimator=SVC(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "qDiVI2VdqIKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 27: Train a Random Forest Classifier with different numbers of trees and compare accuracy"
      ],
      "metadata": {
        "id": "DCD6E3atqISz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in [10, 50, 100]:\n",
        "    rf = RandomForestClassifier(n_estimators=n)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"{n} trees accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "UdudAxt_qIbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 28: Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score"
      ],
      "metadata": {
        "id": "Ulc1rzAtqIjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "print(\"AUC Score:\", roc_auc_score(y_test, probs))\n"
      ],
      "metadata": {
        "id": "DcAAVXQWqIrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 29: Train a Random Forest Regressor and analyze feature importance scores"
      ],
      "metadata": {
        "id": "ZIuYqqkTqIzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()\n",
        "rf.fit(X, y)\n",
        "importances = rf.feature_importances_\n",
        "print(\"Feature Importances:\", importances)\n"
      ],
      "metadata": {
        "id": "59xX2B6qqI78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 30: Train an ensemble model using both Bagging and Random Forest and compare accuracy"
      ],
      "metadata": {
        "id": "VPJLPBBtqJEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc = BaggingClassifier(DecisionTreeClassifier())\n",
        "rf = RandomForestClassifier()\n",
        "bc.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bc.predict(X_test)))\n",
        "print(\"RF Accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "AV21wzx0qJOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 31: Train a Random Forest Classifier and tune hyperparameters using GridSearchCV"
      ],
      "metadata": {
        "id": "Rh0X6zkeqJWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), params, cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best Params:\", grid.best_params_)\n"
      ],
      "metadata": {
        "id": "0FkLrNUBqJfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 32: Train a Bagging Regressor with different numbers of base estimators and compare performance"
      ],
      "metadata": {
        "id": "AiBhBLOZqJoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n in [5, 10, 20]:\n",
        "    model = BaggingRegressor(n_estimators=n)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"{n} estimators MSE:\", mean_squared_error(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "ukMHAzgFqJxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 33: Train a Random Forest Classifier and analyze misclassified samples"
      ],
      "metadata": {
        "id": "SeDOmgmaqJ66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "misclassified = X_test[y_test != y_pred]\n",
        "print(\"Misclassified Samples:\", misclassified)\n"
      ],
      "metadata": {
        "id": "xuRrJRz3qKDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 34: Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier"
      ],
      "metadata": {
        "id": "_YhCsHomqKMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "bag = BaggingClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\n",
        "print(\"DT Accuracy:\", accuracy_score(y_test, dt.predict(X_test)))\n",
        "print(\"Bagging Accuracy:\", accuracy_score(y_test, bag.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "dgMaZKLVqKUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 35: Train a Random Forest Classifier and visualize the confusion matrix"
      ],
      "metadata": {
        "id": "OgEjOcPMqKdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "model = RandomForestClassifier().fit(X_train, y_train)\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "Qnmp15k5qKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 36: Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy"
      ],
      "metadata": {
        "id": "L4Ve6ushqKxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "estimators = [('dt', DecisionTreeClassifier()), ('svm', SVC(probability=True))]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, stack.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "rGWcXa_zqK6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 37: Train a Random Forest Classifier and print the top 5 most important features"
      ],
      "metadata": {
        "id": "B3yj9cjkqLDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model = RandomForestClassifier().fit(X, y)\n",
        "importances = model.feature_importances_\n",
        "top_indices = np.argsort(importances)[-5:][::-1]\n",
        "for i in top_indices:\n",
        "    print(f\"Feature {i}: {importances[i]}\")\n"
      ],
      "metadata": {
        "id": "0LYTMUk7qLL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 38: Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score"
      ],
      "metadata": {
        "id": "VJ7UBwKwroJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "model = BaggingClassifier().fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "m-zZs12frjtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 39: Train a Random Forest Classifier and analyze the effect of max_depth on accuracy"
      ],
      "metadata": {
        "id": "HOSFMZPorkOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for depth in [3, 5, 10, None]:\n",
        "    model = RandomForestClassifier(max_depth=depth)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Max depth {depth}: Accuracy = {accuracy_score(y_test, model.predict(X_test))}\")\n"
      ],
      "metadata": {
        "id": "HPxqv0FfrkXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 40: Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance"
      ],
      "metadata": {
        "id": "HSRdwcRqrkf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "dt_model = BaggingRegressor(base_estimator=DecisionTreeRegressor()).fit(X_train, y_train)\n",
        "knn_model = BaggingRegressor(base_estimator=KNeighborsRegressor()).fit(X_train, y_train)\n",
        "\n",
        "print(\"DT Regressor MSE:\", mean_squared_error(y_test, dt_model.predict(X_test)))\n",
        "print(\"KNN Regressor MSE:\", mean_squared_error(y_test, knn_model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "U38mx9Y-rkop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 41: Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score"
      ],
      "metadata": {
        "id": "e8o569TorlKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, probs))\n"
      ],
      "metadata": {
        "id": "yBwvmXPGrlTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 42: Train a Bagging Classifier and evaluate its performance using cross-validation"
      ],
      "metadata": {
        "id": "KyiKaVE7rlcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(BaggingClassifier(), X, y, cv=5)\n",
        "print(\"Cross-Val Accuracy:\", scores.mean())\n"
      ],
      "metadata": {
        "id": "yz0BeJmqrllW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 43: Train a Random Forest Classifier and plot the Precision-Recall curve\n"
      ],
      "metadata": {
        "id": "ktHyiXmzrmSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
        "PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n"
      ],
      "metadata": {
        "id": "hW99QHWTrma7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 44: Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy"
      ],
      "metadata": {
        "id": "stjl-Hzorm6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [('rf', RandomForestClassifier()), ('lr', LogisticRegression())]\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, stack.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "0M5zV76vsRyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 45: Train a Bagging Regressor with different levels of bootstrap samples and compare performance"
      ],
      "metadata": {
        "id": "ZlNBrahbrjfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for max_samples in [0.5, 0.7, 1.0]:\n",
        "    model = BaggingRegressor(max_samples=max_samples)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Bootstrap {max_samples}: MSE = {mean_squared_error(y_test, model.predict(X_test))}\")\n"
      ],
      "metadata": {
        "id": "elXOyDSnsSao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}